{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "938 157\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device=torch.device(type=\"cuda\",index=0)\n",
    "else:\n",
    "    device=torch.device(type=\"cpu\",index=0)\n",
    "\n",
    "print(device)\n",
    "\n",
    "class CustomTrainDataset(Dataset):\n",
    "    def __init__(self,path, transform):\n",
    "        super().__init__()\n",
    "        self.data=pd.read_csv(path,header='infer').values\n",
    "        self.length=self.data.shape[0]\n",
    "        self.transform=transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        flatimage=self.data[idx,1:].astype(np.uint8)\n",
    "        image=self.transform(np.reshape(flatimage,(28,28,1)))\n",
    "        label=self.data[idx,0]\n",
    "        return image,label\n",
    "\n",
    "class CustomTestDataset(Dataset):\n",
    "    def __init__(self,path, transform):\n",
    "        super().__init__()\n",
    "        self.data=pd.read_csv(path,header='infer').values\n",
    "        self.length=self.data.shape[0]\n",
    "        self.transform=transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        flatimage=self.data[idx,:].astype(np.uint8)\n",
    "        image=self.transform(np.reshape(flatimage,(28,28,1)))\n",
    "        return image\n",
    "    \n",
    "# train_dataset=CustomTrainDataset('/kaggle/input/digit-recognizer/train.csv', ToTensor())\n",
    "# test_dataset=CustomTestDataset('/kaggle/input/digit-recognizer/test.csv', ToTensor())\n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "test_dataset=datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "batch_size=64\n",
    "train_dl=DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "test_dl=DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size, \n",
    ")\n",
    "\n",
    "print(len(train_dl), len(test_dl))  \n",
    "\n",
    "class DRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.relu=nn.ReLU()\n",
    "        self.conv1=nn.Conv2d(in_channels=1,out_channels=8, kernel_size=(3,3), stride=1, padding=0)\n",
    "        self.bn1=nn.BatchNorm2d(8)\n",
    "        self.mp1=nn.MaxPool2d(kernel_size=(2,2),stride=2,padding=0)\n",
    "        \n",
    "        self.conv2=nn.Conv2d(in_channels=8,out_channels=16, kernel_size=(3,3), stride=1, padding=0)\n",
    "        self.bn2=nn.BatchNorm2d(16)\n",
    "        \n",
    "        self.conv3=nn.Conv2d(in_channels=16,out_channels=32, kernel_size=(3,3), stride=1, padding=0)\n",
    "        self.bn3=nn.BatchNorm2d(32)\n",
    "\n",
    "        self.conv4=nn.Conv2d(in_channels=32,out_channels=64, kernel_size=(3,3), stride=1, padding=0)\n",
    "        self.bn4=nn.BatchNorm2d(64)\n",
    "               \n",
    "        self.flatten=nn.Flatten()\n",
    "\n",
    "        self.lin1=nn.Linear(in_features=3136, out_features=10)\n",
    "        self.bn5=nn.BatchNorm1d(num_features=10)\n",
    "            \n",
    "    def forward(self,x):\n",
    "        x=self.conv1(x)\n",
    "        x=self.bn1(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.mp1(x)\n",
    "        \n",
    "        x=self.conv2(x)\n",
    "        x=self.bn2(x)\n",
    "        x=self.relu(x)\n",
    "        \n",
    "        x=self.conv3(x)\n",
    "        x=self.bn3(x)\n",
    "        x=self.relu(x)\n",
    "\n",
    "        x=self.conv4(x)\n",
    "        x=self.bn4(x)\n",
    "        x=self.relu(x)\n",
    "\n",
    "        x=self.flatten(x)\n",
    "\n",
    "        x=self.lin1(x)\n",
    "        output=self.bn5(x)\n",
    "\n",
    "        return output\n",
    "    \n",
    "def train_one_epoch(dataloader, model,loss_fn, optimizer):\n",
    "    model.train()\n",
    "    track_loss=0\n",
    "    num_correct=0\n",
    "    for i, (imgs, labels) in enumerate(dataloader):\n",
    "        imgs=imgs.to(device)\n",
    "        labels=labels.to(device)\n",
    "        pred=model(imgs)\n",
    "                    \n",
    "        loss=loss_fn(pred,labels)\n",
    "        track_loss+=loss.item()\n",
    "        num_correct+=(torch.argmax(pred,dim=1)==labels).type(torch.float).sum().item()\n",
    "        \n",
    "        running_loss=round(track_loss/(i+(imgs.shape[0]/batch_size)),2)\n",
    "        running_acc=round((num_correct/((i*batch_size+imgs.shape[0])))*100,2)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if i%100==0:\n",
    "            print(\"Batch:\", i+1, \"/\",len(dataloader), \"Running Loss:\",running_loss, \"Running Accuracy:\",running_acc)\n",
    "            \n",
    "    epoch_loss=running_loss\n",
    "    epoch_acc=running_acc\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def eval(dataloader, model,loss_fn, path):\n",
    "    model.eval()\n",
    "    data=pd.read_csv(path)\n",
    "    with torch.no_grad():\n",
    "        for i, imgs in enumerate(dataloader):\n",
    "            imgs=imgs.to(device)\n",
    "            pred=model(imgs)\n",
    "            \n",
    "            pred=torch.argmax(pred,dim=1).type(torch.int).cpu()\n",
    "            data.iloc[i*batch_size:i*batch_size+batch_size ,1]=pred.numpy()\n",
    "    \n",
    "    data.to_csv('submission.csv', index=False)\n",
    "    data.head()\n",
    "            \n",
    "            \n",
    "\n",
    "model=DRNN()\n",
    "model=model.to(device)\n",
    "loss_fn=nn.CrossEntropyLoss()\n",
    "lr=0.001\n",
    "#optimizer=torch.optim.SGD(params=model.parameters(), lr=lr)\n",
    "optimizer=torch.optim.Adam(params=model.parameters(), lr=lr)\n",
    "n_epochs=30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch No: 1\n",
      "Batch: 1 / 938 Running Loss: 2.73 Running Accuracy: 4.69\n",
      "Batch: 101 / 938 Running Loss: 0.67 Running Accuracy: 90.02\n",
      "Batch: 201 / 938 Running Loss: 0.55 Running Accuracy: 93.17\n",
      "Batch: 301 / 938 Running Loss: 0.48 Running Accuracy: 94.58\n",
      "Batch: 401 / 938 Running Loss: 0.44 Running Accuracy: 95.33\n",
      "Batch: 501 / 938 Running Loss: 0.4 Running Accuracy: 95.83\n",
      "Batch: 601 / 938 Running Loss: 0.37 Running Accuracy: 96.19\n",
      "Batch: 701 / 938 Running Loss: 0.35 Running Accuracy: 96.49\n",
      "Batch: 801 / 938 Running Loss: 0.33 Running Accuracy: 96.72\n",
      "Batch: 901 / 938 Running Loss: 0.31 Running Accuracy: 96.91\n",
      "Training: Epoch Loss: 0.31 Epoch Accuracy: 96.97\n",
      "--------------------------------------------------\n",
      "Epoch No: 2\n",
      "Batch: 1 / 938 Running Loss: 0.18 Running Accuracy: 96.88\n",
      "Batch: 101 / 938 Running Loss: 0.14 Running Accuracy: 99.04\n",
      "Batch: 201 / 938 Running Loss: 0.14 Running Accuracy: 98.91\n",
      "Batch: 301 / 938 Running Loss: 0.13 Running Accuracy: 98.87\n",
      "Batch: 401 / 938 Running Loss: 0.13 Running Accuracy: 98.85\n",
      "Batch: 501 / 938 Running Loss: 0.13 Running Accuracy: 98.74\n",
      "Batch: 601 / 938 Running Loss: 0.12 Running Accuracy: 98.74\n",
      "Batch: 701 / 938 Running Loss: 0.12 Running Accuracy: 98.76\n",
      "Batch: 801 / 938 Running Loss: 0.12 Running Accuracy: 98.77\n",
      "Batch: 901 / 938 Running Loss: 0.11 Running Accuracy: 98.77\n",
      "Training: Epoch Loss: 0.11 Epoch Accuracy: 98.75\n",
      "--------------------------------------------------\n",
      "Epoch No: 3\n",
      "Batch: 1 / 938 Running Loss: 0.06 Running Accuracy: 100.0\n",
      "Batch: 101 / 938 Running Loss: 0.08 Running Accuracy: 99.15\n",
      "Batch: 201 / 938 Running Loss: 0.08 Running Accuracy: 99.13\n",
      "Batch: 301 / 938 Running Loss: 0.07 Running Accuracy: 99.17\n",
      "Batch: 401 / 938 Running Loss: 0.07 Running Accuracy: 99.15\n",
      "Batch: 501 / 938 Running Loss: 0.07 Running Accuracy: 99.08\n",
      "Batch: 601 / 938 Running Loss: 0.07 Running Accuracy: 99.06\n",
      "Batch: 701 / 938 Running Loss: 0.07 Running Accuracy: 99.03\n",
      "Batch: 801 / 938 Running Loss: 0.07 Running Accuracy: 99.03\n",
      "Batch: 901 / 938 Running Loss: 0.07 Running Accuracy: 99.03\n",
      "Training: Epoch Loss: 0.07 Epoch Accuracy: 99.03\n",
      "--------------------------------------------------\n",
      "Epoch No: 4\n",
      "Batch: 1 / 938 Running Loss: 0.12 Running Accuracy: 98.44\n",
      "Batch: 101 / 938 Running Loss: 0.06 Running Accuracy: 99.3\n",
      "Batch: 201 / 938 Running Loss: 0.05 Running Accuracy: 99.24\n",
      "Batch: 301 / 938 Running Loss: 0.05 Running Accuracy: 99.22\n",
      "Batch: 401 / 938 Running Loss: 0.05 Running Accuracy: 99.16\n",
      "Batch: 501 / 938 Running Loss: 0.05 Running Accuracy: 99.16\n",
      "Batch: 601 / 938 Running Loss: 0.05 Running Accuracy: 99.16\n",
      "Batch: 701 / 938 Running Loss: 0.05 Running Accuracy: 99.17\n",
      "Batch: 801 / 938 Running Loss: 0.05 Running Accuracy: 99.2\n",
      "Batch: 901 / 938 Running Loss: 0.05 Running Accuracy: 99.19\n",
      "Training: Epoch Loss: 0.05 Epoch Accuracy: 99.19\n",
      "--------------------------------------------------\n",
      "Epoch No: 5\n",
      "Batch: 1 / 938 Running Loss: 0.03 Running Accuracy: 98.44\n",
      "Batch: 101 / 938 Running Loss: 0.03 Running Accuracy: 99.43\n",
      "Batch: 201 / 938 Running Loss: 0.04 Running Accuracy: 99.43\n",
      "Batch: 301 / 938 Running Loss: 0.04 Running Accuracy: 99.44\n",
      "Batch: 401 / 938 Running Loss: 0.04 Running Accuracy: 99.47\n",
      "Batch: 501 / 938 Running Loss: 0.04 Running Accuracy: 99.44\n",
      "Batch: 601 / 938 Running Loss: 0.04 Running Accuracy: 99.39\n",
      "Batch: 701 / 938 Running Loss: 0.04 Running Accuracy: 99.34\n",
      "Batch: 801 / 938 Running Loss: 0.04 Running Accuracy: 99.32\n",
      "Batch: 901 / 938 Running Loss: 0.04 Running Accuracy: 99.3\n",
      "Training: Epoch Loss: 0.04 Epoch Accuracy: 99.3\n",
      "--------------------------------------------------\n",
      "Epoch No: 6\n",
      "Batch: 1 / 938 Running Loss: 0.01 Running Accuracy: 100.0\n",
      "Batch: 101 / 938 Running Loss: 0.03 Running Accuracy: 99.58\n",
      "Batch: 201 / 938 Running Loss: 0.03 Running Accuracy: 99.48\n",
      "Batch: 301 / 938 Running Loss: 0.03 Running Accuracy: 99.5\n",
      "Batch: 401 / 938 Running Loss: 0.03 Running Accuracy: 99.52\n",
      "Batch: 501 / 938 Running Loss: 0.03 Running Accuracy: 99.49\n",
      "Batch: 601 / 938 Running Loss: 0.03 Running Accuracy: 99.45\n",
      "Batch: 701 / 938 Running Loss: 0.03 Running Accuracy: 99.43\n",
      "Batch: 801 / 938 Running Loss: 0.03 Running Accuracy: 99.4\n",
      "Batch: 901 / 938 Running Loss: 0.03 Running Accuracy: 99.4\n",
      "Training: Epoch Loss: 0.03 Epoch Accuracy: 99.4\n",
      "--------------------------------------------------\n",
      "Epoch No: 7\n",
      "Batch: 1 / 938 Running Loss: 0.01 Running Accuracy: 100.0\n",
      "Batch: 101 / 938 Running Loss: 0.02 Running Accuracy: 99.6\n",
      "Batch: 201 / 938 Running Loss: 0.03 Running Accuracy: 99.45\n",
      "Batch: 301 / 938 Running Loss: 0.03 Running Accuracy: 99.47\n",
      "Batch: 401 / 938 Running Loss: 0.03 Running Accuracy: 99.47\n",
      "Batch: 501 / 938 Running Loss: 0.03 Running Accuracy: 99.49\n",
      "Batch: 601 / 938 Running Loss: 0.03 Running Accuracy: 99.46\n",
      "Batch: 701 / 938 Running Loss: 0.03 Running Accuracy: 99.43\n",
      "Batch: 801 / 938 Running Loss: 0.03 Running Accuracy: 99.46\n",
      "Batch: 901 / 938 Running Loss: 0.03 Running Accuracy: 99.45\n",
      "Training: Epoch Loss: 0.03 Epoch Accuracy: 99.44\n",
      "--------------------------------------------------\n",
      "Epoch No: 8\n",
      "Batch: 1 / 938 Running Loss: 0.04 Running Accuracy: 98.44\n",
      "Batch: 101 / 938 Running Loss: 0.02 Running Accuracy: 99.64\n",
      "Batch: 201 / 938 Running Loss: 0.02 Running Accuracy: 99.7\n",
      "Batch: 301 / 938 Running Loss: 0.02 Running Accuracy: 99.71\n",
      "Batch: 401 / 938 Running Loss: 0.02 Running Accuracy: 99.67\n",
      "Batch: 501 / 938 Running Loss: 0.02 Running Accuracy: 99.63\n",
      "Batch: 601 / 938 Running Loss: 0.02 Running Accuracy: 99.57\n",
      "Batch: 701 / 938 Running Loss: 0.02 Running Accuracy: 99.55\n",
      "Batch: 801 / 938 Running Loss: 0.02 Running Accuracy: 99.56\n",
      "Batch: 901 / 938 Running Loss: 0.02 Running Accuracy: 99.56\n",
      "Training: Epoch Loss: 0.02 Epoch Accuracy: 99.56\n",
      "--------------------------------------------------\n",
      "Epoch No: 9\n",
      "Batch: 1 / 938 Running Loss: 0.03 Running Accuracy: 98.44\n",
      "Batch: 101 / 938 Running Loss: 0.02 Running Accuracy: 99.69\n",
      "Batch: 201 / 938 Running Loss: 0.02 Running Accuracy: 99.75\n",
      "Batch: 301 / 938 Running Loss: 0.02 Running Accuracy: 99.71\n",
      "Batch: 401 / 938 Running Loss: 0.02 Running Accuracy: 99.7\n",
      "Batch: 501 / 938 Running Loss: 0.02 Running Accuracy: 99.71\n",
      "Batch: 601 / 938 Running Loss: 0.02 Running Accuracy: 99.7\n",
      "Batch: 701 / 938 Running Loss: 0.02 Running Accuracy: 99.68\n",
      "Batch: 801 / 938 Running Loss: 0.02 Running Accuracy: 99.67\n",
      "Batch: 901 / 938 Running Loss: 0.02 Running Accuracy: 99.68\n",
      "Training: Epoch Loss: 0.02 Epoch Accuracy: 99.67\n",
      "--------------------------------------------------\n",
      "Epoch No: 10\n",
      "Batch: 1 / 938 Running Loss: 0.03 Running Accuracy: 100.0\n",
      "Batch: 101 / 938 Running Loss: 0.01 Running Accuracy: 99.71\n",
      "Batch: 201 / 938 Running Loss: 0.01 Running Accuracy: 99.74\n",
      "Batch: 301 / 938 Running Loss: 0.02 Running Accuracy: 99.68\n",
      "Batch: 401 / 938 Running Loss: 0.02 Running Accuracy: 99.63\n",
      "Batch: 501 / 938 Running Loss: 0.02 Running Accuracy: 99.68\n",
      "Batch: 601 / 938 Running Loss: 0.02 Running Accuracy: 99.69\n",
      "Batch: 701 / 938 Running Loss: 0.02 Running Accuracy: 99.67\n",
      "Batch: 801 / 938 Running Loss: 0.02 Running Accuracy: 99.68\n",
      "Batch: 901 / 938 Running Loss: 0.02 Running Accuracy: 99.69\n",
      "Training: Epoch Loss: 0.01 Epoch Accuracy: 99.69\n",
      "--------------------------------------------------\n",
      "Epoch No: 11\n",
      "Batch: 1 / 938 Running Loss: 0.03 Running Accuracy: 98.44\n",
      "Batch: 101 / 938 Running Loss: 0.01 Running Accuracy: 99.71\n",
      "Batch: 201 / 938 Running Loss: 0.01 Running Accuracy: 99.73\n",
      "Batch: 301 / 938 Running Loss: 0.01 Running Accuracy: 99.74\n",
      "Batch: 401 / 938 Running Loss: 0.01 Running Accuracy: 99.77\n",
      "Batch: 501 / 938 Running Loss: 0.01 Running Accuracy: 99.75\n",
      "Batch: 601 / 938 Running Loss: 0.01 Running Accuracy: 99.75\n",
      "Batch: 701 / 938 Running Loss: 0.01 Running Accuracy: 99.74\n",
      "Batch: 801 / 938 Running Loss: 0.01 Running Accuracy: 99.73\n",
      "Batch: 901 / 938 Running Loss: 0.01 Running Accuracy: 99.71\n",
      "Training: Epoch Loss: 0.01 Epoch Accuracy: 99.71\n",
      "--------------------------------------------------\n",
      "Epoch No: 12\n",
      "Batch: 1 / 938 Running Loss: 0.01 Running Accuracy: 100.0\n",
      "Batch: 101 / 938 Running Loss: 0.01 Running Accuracy: 99.81\n",
      "Batch: 201 / 938 Running Loss: 0.01 Running Accuracy: 99.82\n",
      "Batch: 301 / 938 Running Loss: 0.01 Running Accuracy: 99.8\n",
      "Batch: 401 / 938 Running Loss: 0.01 Running Accuracy: 99.82\n",
      "Batch: 501 / 938 Running Loss: 0.01 Running Accuracy: 99.8\n",
      "Batch: 601 / 938 Running Loss: 0.01 Running Accuracy: 99.79\n",
      "Batch: 701 / 938 Running Loss: 0.01 Running Accuracy: 99.79\n",
      "Batch: 801 / 938 Running Loss: 0.01 Running Accuracy: 99.79\n",
      "Batch: 901 / 938 Running Loss: 0.01 Running Accuracy: 99.78\n",
      "Training: Epoch Loss: 0.01 Epoch Accuracy: 99.78\n",
      "--------------------------------------------------\n",
      "Epoch No: 13\n",
      "Batch: 1 / 938 Running Loss: 0.01 Running Accuracy: 100.0\n",
      "Batch: 101 / 938 Running Loss: 0.01 Running Accuracy: 99.72\n",
      "Batch: 201 / 938 Running Loss: 0.01 Running Accuracy: 99.77\n",
      "Batch: 301 / 938 Running Loss: 0.01 Running Accuracy: 99.79\n",
      "Batch: 401 / 938 Running Loss: 0.01 Running Accuracy: 99.81\n",
      "Batch: 501 / 938 Running Loss: 0.01 Running Accuracy: 99.81\n",
      "Batch: 601 / 938 Running Loss: 0.01 Running Accuracy: 99.79\n",
      "Batch: 701 / 938 Running Loss: 0.01 Running Accuracy: 99.77\n",
      "Batch: 801 / 938 Running Loss: 0.01 Running Accuracy: 99.76\n",
      "Batch: 901 / 938 Running Loss: 0.01 Running Accuracy: 99.75\n",
      "Training: Epoch Loss: 0.01 Epoch Accuracy: 99.75\n",
      "--------------------------------------------------\n",
      "Epoch No: 14\n",
      "Batch: 1 / 938 Running Loss: 0.01 Running Accuracy: 100.0\n",
      "Batch: 101 / 938 Running Loss: 0.01 Running Accuracy: 99.91\n",
      "Batch: 201 / 938 Running Loss: 0.01 Running Accuracy: 99.88\n",
      "Batch: 301 / 938 Running Loss: 0.01 Running Accuracy: 99.84\n",
      "Batch: 401 / 938 Running Loss: 0.01 Running Accuracy: 99.84\n",
      "Batch: 501 / 938 Running Loss: 0.01 Running Accuracy: 99.83\n",
      "Batch: 601 / 938 Running Loss: 0.01 Running Accuracy: 99.82\n",
      "Batch: 701 / 938 Running Loss: 0.01 Running Accuracy: 99.81\n",
      "Batch: 801 / 938 Running Loss: 0.01 Running Accuracy: 99.8\n",
      "Batch: 901 / 938 Running Loss: 0.01 Running Accuracy: 99.79\n",
      "Training: Epoch Loss: 0.01 Epoch Accuracy: 99.79\n",
      "--------------------------------------------------\n",
      "Epoch No: 15\n",
      "Batch: 1 / 938 Running Loss: 0.01 Running Accuracy: 100.0\n",
      "Batch: 101 / 938 Running Loss: 0.01 Running Accuracy: 99.81\n",
      "Batch: 201 / 938 Running Loss: 0.01 Running Accuracy: 99.82\n",
      "Batch: 301 / 938 Running Loss: 0.01 Running Accuracy: 99.84\n",
      "Batch: 401 / 938 Running Loss: 0.01 Running Accuracy: 99.84\n",
      "Batch: 501 / 938 Running Loss: 0.01 Running Accuracy: 99.85\n",
      "Batch: 601 / 938 Running Loss: 0.01 Running Accuracy: 99.83\n",
      "Batch: 701 / 938 Running Loss: 0.01 Running Accuracy: 99.83\n",
      "Batch: 801 / 938 Running Loss: 0.01 Running Accuracy: 99.82\n",
      "Batch: 901 / 938 Running Loss: 0.01 Running Accuracy: 99.82\n",
      "Training: Epoch Loss: 0.01 Epoch Accuracy: 99.82\n",
      "--------------------------------------------------\n",
      "Epoch No: 16\n",
      "Batch: 1 / 938 Running Loss: 0.02 Running Accuracy: 100.0\n",
      "Batch: 101 / 938 Running Loss: 0.0 Running Accuracy: 99.97\n",
      "Batch: 201 / 938 Running Loss: 0.0 Running Accuracy: 99.93\n",
      "Batch: 301 / 938 Running Loss: 0.01 Running Accuracy: 99.9\n",
      "Batch: 401 / 938 Running Loss: 0.01 Running Accuracy: 99.9\n",
      "Batch: 501 / 938 Running Loss: 0.01 Running Accuracy: 99.89\n",
      "Batch: 601 / 938 Running Loss: 0.01 Running Accuracy: 99.89\n",
      "Batch: 701 / 938 Running Loss: 0.01 Running Accuracy: 99.89\n",
      "Batch: 801 / 938 Running Loss: 0.01 Running Accuracy: 99.88\n",
      "Batch: 901 / 938 Running Loss: 0.01 Running Accuracy: 99.88\n",
      "Training: Epoch Loss: 0.01 Epoch Accuracy: 99.88\n",
      "--------------------------------------------------\n",
      "Epoch No: 17\n",
      "Batch: 1 / 938 Running Loss: 0.0 Running Accuracy: 100.0\n",
      "Batch: 101 / 938 Running Loss: 0.01 Running Accuracy: 99.86\n",
      "Batch: 201 / 938 Running Loss: 0.01 Running Accuracy: 99.88\n",
      "Batch: 301 / 938 Running Loss: 0.0 Running Accuracy: 99.9\n",
      "Batch: 401 / 938 Running Loss: 0.0 Running Accuracy: 99.9\n",
      "Batch: 501 / 938 Running Loss: 0.0 Running Accuracy: 99.91\n",
      "Batch: 601 / 938 Running Loss: 0.0 Running Accuracy: 99.92\n",
      "Batch: 701 / 938 Running Loss: 0.01 Running Accuracy: 99.91\n",
      "Batch: 801 / 938 Running Loss: 0.01 Running Accuracy: 99.89\n",
      "Batch: 901 / 938 Running Loss: 0.01 Running Accuracy: 99.88\n",
      "Training: Epoch Loss: 0.01 Epoch Accuracy: 99.88\n",
      "--------------------------------------------------\n",
      "Epoch No: 18\n",
      "Batch: 1 / 938 Running Loss: 0.01 Running Accuracy: 100.0\n",
      "Batch: 101 / 938 Running Loss: 0.01 Running Accuracy: 99.92\n",
      "Batch: 201 / 938 Running Loss: 0.01 Running Accuracy: 99.87\n",
      "Batch: 301 / 938 Running Loss: 0.01 Running Accuracy: 99.88\n",
      "Batch: 401 / 938 Running Loss: 0.01 Running Accuracy: 99.88\n",
      "Batch: 501 / 938 Running Loss: 0.01 Running Accuracy: 99.88\n",
      "Batch: 601 / 938 Running Loss: 0.01 Running Accuracy: 99.87\n",
      "Batch: 701 / 938 Running Loss: 0.01 Running Accuracy: 99.88\n",
      "Batch: 801 / 938 Running Loss: 0.01 Running Accuracy: 99.88\n",
      "Batch: 901 / 938 Running Loss: 0.01 Running Accuracy: 99.87\n",
      "Training: Epoch Loss: 0.01 Epoch Accuracy: 99.87\n",
      "--------------------------------------------------\n",
      "Epoch No: 19\n",
      "Batch: 1 / 938 Running Loss: 0.0 Running Accuracy: 100.0\n",
      "Batch: 101 / 938 Running Loss: 0.0 Running Accuracy: 99.97\n",
      "Batch: 201 / 938 Running Loss: 0.0 Running Accuracy: 99.93\n",
      "Batch: 301 / 938 Running Loss: 0.0 Running Accuracy: 99.93\n",
      "Batch: 401 / 938 Running Loss: 0.0 Running Accuracy: 99.93\n",
      "Batch: 501 / 938 Running Loss: 0.0 Running Accuracy: 99.94\n",
      "Batch: 601 / 938 Running Loss: 0.0 Running Accuracy: 99.92\n",
      "Batch: 701 / 938 Running Loss: 0.0 Running Accuracy: 99.92\n",
      "Batch: 801 / 938 Running Loss: 0.0 Running Accuracy: 99.91\n",
      "Batch: 901 / 938 Running Loss: 0.0 Running Accuracy: 99.91\n",
      "Training: Epoch Loss: 0.0 Epoch Accuracy: 99.91\n",
      "--------------------------------------------------\n",
      "Epoch No: 20\n",
      "Batch: 1 / 938 Running Loss: 0.0 Running Accuracy: 100.0\n",
      "Batch: 101 / 938 Running Loss: 0.01 Running Accuracy: 99.91\n",
      "Batch: 201 / 938 Running Loss: 0.01 Running Accuracy: 99.91\n",
      "Batch: 301 / 938 Running Loss: 0.0 Running Accuracy: 99.91\n",
      "Batch: 401 / 938 Running Loss: 0.0 Running Accuracy: 99.93\n",
      "Batch: 501 / 938 Running Loss: 0.0 Running Accuracy: 99.92\n",
      "Batch: 601 / 938 Running Loss: 0.0 Running Accuracy: 99.93\n",
      "Batch: 701 / 938 Running Loss: 0.0 Running Accuracy: 99.92\n",
      "Batch: 801 / 938 Running Loss: 0.0 Running Accuracy: 99.92\n",
      "Batch: 901 / 938 Running Loss: 0.0 Running Accuracy: 99.93\n",
      "Training: Epoch Loss: 0.0 Epoch Accuracy: 99.92\n",
      "--------------------------------------------------\n",
      "Epoch No: 21\n",
      "Batch: 1 / 938 Running Loss: 0.0 Running Accuracy: 100.0\n",
      "Batch: 101 / 938 Running Loss: 0.0 Running Accuracy: 99.88\n",
      "Batch: 201 / 938 Running Loss: 0.0 Running Accuracy: 99.9\n",
      "Batch: 301 / 938 Running Loss: 0.0 Running Accuracy: 99.93\n",
      "Batch: 401 / 938 Running Loss: 0.0 Running Accuracy: 99.91\n",
      "Batch: 501 / 938 Running Loss: 0.01 Running Accuracy: 99.88\n",
      "Batch: 601 / 938 Running Loss: 0.01 Running Accuracy: 99.86\n",
      "Batch: 701 / 938 Running Loss: 0.01 Running Accuracy: 99.86\n",
      "Batch: 801 / 938 Running Loss: 0.01 Running Accuracy: 99.86\n",
      "Batch: 901 / 938 Running Loss: 0.01 Running Accuracy: 99.84\n",
      "Training: Epoch Loss: 0.01 Epoch Accuracy: 99.84\n",
      "--------------------------------------------------\n",
      "Epoch No: 22\n",
      "Batch: 1 / 938 Running Loss: 0.0 Running Accuracy: 100.0\n",
      "Batch: 101 / 938 Running Loss: 0.01 Running Accuracy: 99.88\n",
      "Batch: 201 / 938 Running Loss: 0.01 Running Accuracy: 99.87\n",
      "Batch: 301 / 938 Running Loss: 0.01 Running Accuracy: 99.88\n",
      "Batch: 401 / 938 Running Loss: 0.0 Running Accuracy: 99.88\n",
      "Batch: 501 / 938 Running Loss: 0.0 Running Accuracy: 99.89\n",
      "Batch: 601 / 938 Running Loss: 0.0 Running Accuracy: 99.89\n",
      "Batch: 701 / 938 Running Loss: 0.0 Running Accuracy: 99.89\n",
      "Batch: 801 / 938 Running Loss: 0.01 Running Accuracy: 99.88\n",
      "Batch: 901 / 938 Running Loss: 0.0 Running Accuracy: 99.88\n",
      "Training: Epoch Loss: 0.0 Epoch Accuracy: 99.88\n",
      "--------------------------------------------------\n",
      "Epoch No: 23\n",
      "Batch: 1 / 938 Running Loss: 0.0 Running Accuracy: 100.0\n",
      "Batch: 101 / 938 Running Loss: 0.0 Running Accuracy: 99.92\n",
      "Batch: 201 / 938 Running Loss: 0.0 Running Accuracy: 99.92\n",
      "Batch: 301 / 938 Running Loss: 0.0 Running Accuracy: 99.91\n",
      "Batch: 401 / 938 Running Loss: 0.0 Running Accuracy: 99.91\n",
      "Batch: 501 / 938 Running Loss: 0.0 Running Accuracy: 99.89\n",
      "Batch: 601 / 938 Running Loss: 0.0 Running Accuracy: 99.9\n",
      "Batch: 701 / 938 Running Loss: 0.0 Running Accuracy: 99.9\n",
      "Batch: 801 / 938 Running Loss: 0.0 Running Accuracy: 99.9\n",
      "Batch: 901 / 938 Running Loss: 0.0 Running Accuracy: 99.9\n",
      "Training: Epoch Loss: 0.0 Epoch Accuracy: 99.9\n",
      "--------------------------------------------------\n",
      "Epoch No: 24\n",
      "Batch: 1 / 938 Running Loss: 0.0 Running Accuracy: 100.0\n",
      "Batch: 101 / 938 Running Loss: 0.0 Running Accuracy: 99.95\n",
      "Batch: 201 / 938 Running Loss: 0.0 Running Accuracy: 99.95\n",
      "Batch: 301 / 938 Running Loss: 0.0 Running Accuracy: 99.95\n",
      "Batch: 401 / 938 Running Loss: 0.0 Running Accuracy: 99.94\n",
      "Batch: 501 / 938 Running Loss: 0.0 Running Accuracy: 99.93\n",
      "Batch: 601 / 938 Running Loss: 0.0 Running Accuracy: 99.92\n",
      "Batch: 701 / 938 Running Loss: 0.0 Running Accuracy: 99.93\n",
      "Batch: 801 / 938 Running Loss: 0.0 Running Accuracy: 99.93\n",
      "Batch: 901 / 938 Running Loss: 0.0 Running Accuracy: 99.92\n",
      "Training: Epoch Loss: 0.0 Epoch Accuracy: 99.92\n",
      "--------------------------------------------------\n",
      "Epoch No: 25\n",
      "Batch: 1 / 938 Running Loss: 0.0 Running Accuracy: 100.0\n",
      "Batch: 101 / 938 Running Loss: 0.0 Running Accuracy: 99.94\n",
      "Batch: 201 / 938 Running Loss: 0.01 Running Accuracy: 99.88\n",
      "Batch: 301 / 938 Running Loss: 0.01 Running Accuracy: 99.89\n",
      "Batch: 401 / 938 Running Loss: 0.01 Running Accuracy: 99.89\n",
      "Batch: 501 / 938 Running Loss: 0.01 Running Accuracy: 99.88\n",
      "Batch: 601 / 938 Running Loss: 0.0 Running Accuracy: 99.9\n",
      "Batch: 701 / 938 Running Loss: 0.0 Running Accuracy: 99.9\n",
      "Batch: 801 / 938 Running Loss: 0.0 Running Accuracy: 99.89\n",
      "Batch: 901 / 938 Running Loss: 0.0 Running Accuracy: 99.9\n",
      "Training: Epoch Loss: 0.0 Epoch Accuracy: 99.9\n",
      "--------------------------------------------------\n",
      "Epoch No: 26\n",
      "Batch: 1 / 938 Running Loss: 0.0 Running Accuracy: 100.0\n",
      "Batch: 101 / 938 Running Loss: 0.0 Running Accuracy: 99.92\n",
      "Batch: 201 / 938 Running Loss: 0.0 Running Accuracy: 99.92\n",
      "Batch: 301 / 938 Running Loss: 0.0 Running Accuracy: 99.92\n",
      "Batch: 401 / 938 Running Loss: 0.0 Running Accuracy: 99.93\n",
      "Batch: 501 / 938 Running Loss: 0.0 Running Accuracy: 99.94\n",
      "Batch: 601 / 938 Running Loss: 0.0 Running Accuracy: 99.94\n",
      "Batch: 701 / 938 Running Loss: 0.0 Running Accuracy: 99.94\n",
      "Batch: 801 / 938 Running Loss: 0.0 Running Accuracy: 99.95\n",
      "Batch: 901 / 938 Running Loss: 0.0 Running Accuracy: 99.95\n",
      "Training: Epoch Loss: 0.0 Epoch Accuracy: 99.95\n",
      "--------------------------------------------------\n",
      "Epoch No: 27\n",
      "Batch: 1 / 938 Running Loss: 0.0 Running Accuracy: 100.0\n",
      "Batch: 101 / 938 Running Loss: 0.0 Running Accuracy: 100.0\n",
      "Batch: 201 / 938 Running Loss: 0.0 Running Accuracy: 99.99\n",
      "Batch: 301 / 938 Running Loss: 0.0 Running Accuracy: 99.96\n",
      "Batch: 401 / 938 Running Loss: 0.0 Running Accuracy: 99.95\n",
      "Batch: 501 / 938 Running Loss: 0.0 Running Accuracy: 99.93\n",
      "Batch: 601 / 938 Running Loss: 0.0 Running Accuracy: 99.93\n",
      "Batch: 701 / 938 Running Loss: 0.0 Running Accuracy: 99.94\n",
      "Batch: 801 / 938 Running Loss: 0.0 Running Accuracy: 99.93\n",
      "Batch: 901 / 938 Running Loss: 0.0 Running Accuracy: 99.92\n",
      "Training: Epoch Loss: 0.0 Epoch Accuracy: 99.91\n",
      "--------------------------------------------------\n",
      "Epoch No: 28\n",
      "Batch: 1 / 938 Running Loss: 0.01 Running Accuracy: 100.0\n",
      "Batch: 101 / 938 Running Loss: 0.0 Running Accuracy: 99.94\n",
      "Batch: 201 / 938 Running Loss: 0.0 Running Accuracy: 99.91\n",
      "Batch: 301 / 938 Running Loss: 0.0 Running Accuracy: 99.92\n",
      "Batch: 401 / 938 Running Loss: 0.0 Running Accuracy: 99.93\n",
      "Batch: 501 / 938 Running Loss: 0.0 Running Accuracy: 99.93\n",
      "Batch: 601 / 938 Running Loss: 0.0 Running Accuracy: 99.93\n",
      "Batch: 701 / 938 Running Loss: 0.0 Running Accuracy: 99.94\n",
      "Batch: 801 / 938 Running Loss: 0.0 Running Accuracy: 99.93\n",
      "Batch: 901 / 938 Running Loss: 0.0 Running Accuracy: 99.93\n",
      "Training: Epoch Loss: 0.0 Epoch Accuracy: 99.92\n",
      "--------------------------------------------------\n",
      "Epoch No: 29\n",
      "Batch: 1 / 938 Running Loss: 0.0 Running Accuracy: 100.0\n",
      "Batch: 101 / 938 Running Loss: 0.0 Running Accuracy: 99.89\n",
      "Batch: 201 / 938 Running Loss: 0.0 Running Accuracy: 99.94\n",
      "Batch: 301 / 938 Running Loss: 0.0 Running Accuracy: 99.93\n",
      "Batch: 401 / 938 Running Loss: 0.0 Running Accuracy: 99.94\n",
      "Batch: 501 / 938 Running Loss: 0.0 Running Accuracy: 99.94\n",
      "Batch: 601 / 938 Running Loss: 0.0 Running Accuracy: 99.95\n",
      "Batch: 701 / 938 Running Loss: 0.0 Running Accuracy: 99.95\n",
      "Batch: 801 / 938 Running Loss: 0.0 Running Accuracy: 99.94\n",
      "Batch: 901 / 938 Running Loss: 0.0 Running Accuracy: 99.94\n",
      "Training: Epoch Loss: 0.0 Epoch Accuracy: 99.94\n",
      "--------------------------------------------------\n",
      "Epoch No: 30\n",
      "Batch: 1 / 938 Running Loss: 0.0 Running Accuracy: 100.0\n",
      "Batch: 101 / 938 Running Loss: 0.0 Running Accuracy: 99.98\n",
      "Batch: 201 / 938 Running Loss: 0.0 Running Accuracy: 99.98\n",
      "Batch: 301 / 938 Running Loss: 0.0 Running Accuracy: 99.96\n",
      "Batch: 401 / 938 Running Loss: 0.0 Running Accuracy: 99.96\n",
      "Batch: 501 / 938 Running Loss: 0.0 Running Accuracy: 99.95\n",
      "Batch: 601 / 938 Running Loss: 0.0 Running Accuracy: 99.96\n",
      "Batch: 701 / 938 Running Loss: 0.0 Running Accuracy: 99.96\n",
      "Batch: 801 / 938 Running Loss: 0.0 Running Accuracy: 99.95\n",
      "Batch: 901 / 938 Running Loss: 0.0 Running Accuracy: 99.95\n",
      "Training: Epoch Loss: 0.0 Epoch Accuracy: 99.95\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "eval() missing 1 required positional argument: 'path'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch Loss:\u001b[39m\u001b[38;5;124m\"\u001b[39m, train_epoch_loss, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch Accuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, train_epoch_acc)\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--------------------------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;43meval\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: eval() missing 1 required positional argument: 'path'"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(n_epochs):\n",
    "    print(\"Epoch No:\",i+1)\n",
    "    train_epoch_loss, train_epoch_acc=train_one_epoch(train_dl,model,loss_fn,optimizer)\n",
    "    print(\"Training:\", \"Epoch Loss:\", train_epoch_loss, \"Epoch Accuracy:\", train_epoch_acc)\n",
    "    print(\"--------------------------------------------------\")\n",
    "\n",
    "eval(test_dataset, model,loss_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
