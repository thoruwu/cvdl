{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images:  200\n",
      "Image shape:  (256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "# load images from given folder\n",
    "def load_images(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder, filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "\n",
    "datas = load_images('data')\n",
    "print(\"Total images: \", len(datas))\n",
    "print(\"Image shape: \", datas[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R1</th>\n",
       "      <th>G1</th>\n",
       "      <th>B1</th>\n",
       "      <th>R2</th>\n",
       "      <th>G2</th>\n",
       "      <th>B2</th>\n",
       "      <th>R3</th>\n",
       "      <th>G3</th>\n",
       "      <th>B3</th>\n",
       "      <th>R4</th>\n",
       "      <th>...</th>\n",
       "      <th>R14</th>\n",
       "      <th>G14</th>\n",
       "      <th>B14</th>\n",
       "      <th>R15</th>\n",
       "      <th>G15</th>\n",
       "      <th>B15</th>\n",
       "      <th>R16</th>\n",
       "      <th>G16</th>\n",
       "      <th>B16</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103</td>\n",
       "      <td>111</td>\n",
       "      <td>109</td>\n",
       "      <td>108</td>\n",
       "      <td>121</td>\n",
       "      <td>111</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>116</td>\n",
       "      <td>109</td>\n",
       "      <td>...</td>\n",
       "      <td>110</td>\n",
       "      <td>114</td>\n",
       "      <td>112</td>\n",
       "      <td>116</td>\n",
       "      <td>115</td>\n",
       "      <td>127</td>\n",
       "      <td>116</td>\n",
       "      <td>112</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>115</td>\n",
       "      <td>122</td>\n",
       "      <td>116</td>\n",
       "      <td>111</td>\n",
       "      <td>114</td>\n",
       "      <td>115</td>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "      <td>114</td>\n",
       "      <td>111</td>\n",
       "      <td>...</td>\n",
       "      <td>116</td>\n",
       "      <td>116</td>\n",
       "      <td>114</td>\n",
       "      <td>113</td>\n",
       "      <td>112</td>\n",
       "      <td>121</td>\n",
       "      <td>116</td>\n",
       "      <td>126</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115</td>\n",
       "      <td>103</td>\n",
       "      <td>111</td>\n",
       "      <td>109</td>\n",
       "      <td>114</td>\n",
       "      <td>110</td>\n",
       "      <td>107</td>\n",
       "      <td>105</td>\n",
       "      <td>109</td>\n",
       "      <td>109</td>\n",
       "      <td>...</td>\n",
       "      <td>116</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>119</td>\n",
       "      <td>113</td>\n",
       "      <td>111</td>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>116</td>\n",
       "      <td>117</td>\n",
       "      <td>116</td>\n",
       "      <td>121</td>\n",
       "      <td>108</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>102</td>\n",
       "      <td>107</td>\n",
       "      <td>105</td>\n",
       "      <td>...</td>\n",
       "      <td>105</td>\n",
       "      <td>107</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>104</td>\n",
       "      <td>107</td>\n",
       "      <td>103</td>\n",
       "      <td>101</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>144</td>\n",
       "      <td>142</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>151</td>\n",
       "      <td>149</td>\n",
       "      <td>144</td>\n",
       "      <td>153</td>\n",
       "      <td>147</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>143</td>\n",
       "      <td>157</td>\n",
       "      <td>148</td>\n",
       "      <td>147</td>\n",
       "      <td>138</td>\n",
       "      <td>162</td>\n",
       "      <td>174</td>\n",
       "      <td>152</td>\n",
       "      <td>143</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    R1   G1   B1   R2   G2   B2   R3   G3   B3   R4  ...  R14  G14  B14  R15  \\\n",
       "0  103  111  109  108  121  111  113  113  116  109  ...  110  114  112  116   \n",
       "1  115  122  116  111  114  115  117  117  114  111  ...  116  116  114  113   \n",
       "2  115  103  111  109  114  110  107  105  109  109  ...  116  120  120  120   \n",
       "3  116  117  116  121  108  106  106  102  107  105  ...  105  107  103  103   \n",
       "4  144  142  149  149  151  149  144  153  147  150  ...  143  157  148  147   \n",
       "\n",
       "   G15  B15  R16  G16  B16  target  \n",
       "0  115  127  116  112  125       0  \n",
       "1  112  121  116  126  120       0  \n",
       "2  119  113  111  117  117       0  \n",
       "3  104  107  103  101  103       0  \n",
       "4  138  162  174  152  143       0  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract features from given image data using 16x16 grid histogram for each channel\n",
    "grid_size = 64\n",
    "def extract_features(data):\n",
    "    features = []\n",
    "    for img in data:\n",
    "        hist = []\n",
    "        for i in range(3):\n",
    "            for x in range(0, 256, grid_size):\n",
    "                for y in range(0, 256, grid_size):\n",
    "                    hist.append(cv2.calcHist([img[x:x+grid_size, y:y+grid_size, i]], [0], None, [256], [0, 256]).argmax())\n",
    "\n",
    "        features.append(hist)\n",
    "    return pd.DataFrame(features)\n",
    "\n",
    "\n",
    "df = extract_features(datas)\n",
    "output=[0]*100 + [1]*100\n",
    "column_names = []\n",
    "for k in range(1, 17):\n",
    "    column_names.extend([f'R{k}', f'G{k}', f'B{k}'])\n",
    "df.columns = column_names\n",
    "df['target']=output\n",
    "df.to_csv('features.csv', index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9\n"
     ]
    }
   ],
   "source": [
    "# Classification using MLP model with sklearn\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df = pd.read_csv('features.csv')\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100, 100), max_iter=1000)\n",
    "mlp.fit(X_train, y_train)\n",
    "y_pred = mlp.predict(X_test)\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 3.229811668395996\n",
      "Epoch 100, Loss: 0.1266646832227707\n",
      "Epoch 200, Loss: 0.03946523740887642\n",
      "Epoch 300, Loss: 0.002832624129951\n",
      "Epoch 400, Loss: 0.02627333626151085\n",
      "Epoch 500, Loss: 0.0020359810441732407\n",
      "Epoch 600, Loss: 0.001381992595270276\n",
      "Epoch 700, Loss: 0.0004701522411778569\n",
      "Epoch 800, Loss: 0.00029754918068647385\n",
      "Epoch 900, Loss: 3.972342892666347e-05\n",
      "Epoch 1000, Loss: 4.2079474951606244e-05\n",
      "Epoch 1100, Loss: 2.5982757506426424e-05\n",
      "Epoch 1200, Loss: 8.571397302148398e-06\n",
      "Epoch 1300, Loss: 3.6283847748563858e-06\n",
      "Epoch 1400, Loss: 2.931761173385894e-06\n",
      "Epoch 1500, Loss: 4.030667696497403e-06\n",
      "Epoch 1600, Loss: 3.3452643037890084e-06\n",
      "Epoch 1700, Loss: 1.2181629926999449e-06\n",
      "Epoch 1800, Loss: 1.1958115919696866e-06\n",
      "Epoch 1900, Loss: 1.8514560906623956e-06\n",
      "Epoch 2000, Loss: 2.4474838937749155e-06\n",
      "Epoch 2100, Loss: 6.817248845436552e-07\n",
      "Epoch 2200, Loss: 1.676379355330937e-07\n",
      "Epoch 2300, Loss: 1.6018742599044344e-07\n",
      "Epoch 2400, Loss: 7.376058874797309e-07\n",
      "Epoch 2500, Loss: 3.09198640024988e-07\n"
     ]
    }
   ],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data, target):\n",
    "        self.data = torch.tensor(data.values).float()\n",
    "        self.target = torch.tensor(target.values).long()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.target[idx]\n",
    "\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Classification using MLP model with PyTorch\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "train_dataset = ImageDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataset = ImageDataset(X_test, y_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(48, 100)\n",
    "        self.fc2 = nn.Linear(100, 100)\n",
    "        self.fc3 = nn.Linear(100, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "model = MLP()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "epoch = 10000\n",
    "\n",
    "for epoch in range(epoch):\n",
    "    for data, target in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data, target in test_dataloader:\n",
    "        outputs = model(data)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "    \n",
    "\n",
    "print('Accuracy: ', correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
